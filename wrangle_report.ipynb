{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WRITTEN REPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project I have had several difficulties. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all I gather data loading twitter-archive-enhanced.csv in df_1 and I extract the id's from the tweet_id column so that later I can search for them on twitter. Then I load the archive image_predictions.tsv programmatically from Udacity server using requests and l save with os in archive called image_prediciots.tsv. After this I connect twitter APi and I Query this for JSON data for each tweet ID in the Twitter archive and I save in archive called tweet-json.txt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the assessing of the data I load the another data called impage_predicions.tsv and twitter-json.txt into two archives calles df_2 and df_3 respectively. I have had to make many checks in this regard since if the data is viewed in a general way the errors in the dataframe df_1 related to the twitter_archive_enhanced.csv file are not seen. I check the three dataframes searching null values and searching for errors:\n",
    "> In **`enhanced`** At first sight we note that we have null values in the colunns that we are interested:\n",
    "- in_reply_to_status_id (78 non-null values)\n",
    "- in_reply_to_user_id (78 non-null values)\n",
    "- retweeted_status_id (181 non-null values)\n",
    "- retweeted_status_user_id (181 non-null)\n",
    "- retweeted_status_timestamp (181 non-null values)\n",
    "\n",
    "> We note that there are null values in the columns related to reply and reteweted so it is initially believed to correspond to the tweets that are not needed and will be used to filter the data later.The rest of the columns do not have any null value, but maybe we have hidden null values between correct ones.\n",
    "> At first glance we can see that we only have null values in the columns that we need filter for non_null values after which we will check with the json file.\n",
    "> We also observe that the datatype of the column datetime is object.\n",
    "> We observe that the columns related to dog stages (poppo,..) must be in one column.\n",
    "> I note that we have null values hidden in the name of the dogs with 'None' and many names were errors which started with the first letter in lowercase how 'a', 'an', 'the', etc. I also note that in the rating we had errors because the column is in integer and much ratings in the column text are decimals, in addition that there were errors in texts with two ratings or with a non rate in the decription how 1/2 or 24/7 which referred to other things. Regarding the challenge of columns with null values referring to the reply or retweet column, I have only changed them to boolean to be able to filter easily and also to be able to compare with tweet_df referring to tweet-json.txt which are correct, although it will finally be eliminated from the final dataframe once joined. I note too that the datatype of the column timestamp was in string/object which I need change to datetime.\n",
    "\n",
    "> In **`image`** I practically only had to keep the first 3 columns where in the url I will extract the name of the image and then replace it. We also should change the name of jpg_url where we extracted the name to image_name and img_num to image_number.\n",
    "\n",
    "> In **`tweet_df`** related to the tweet-json.txt tweeter file it is observed that there are many columns that we need to delete. We also note that we should change tha nema of the column id to tweet_id for megerging after with the anothers tables. We should extract the rating of the numerator and denominator from the full_text column in the rating_numerator and rating_denominator columns that were erroenus in enhanced table. we should convert the columns related to replies and retweets to one boolean column with True or False."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding cleaning, I emphasize that I had to use the functions to convert the timestamp data that was in object to datetime. I have also obtained that extracting the values of the name, rating numerator and rating denominator from the tweet-json.txt file with regex which has cost me a lot of time. In the same way, many techniques learned throughout the lesson have been used massively to be able to clean the data well how rename function for rename the columns, drop function for remove many columns, np.nan for fill null values in the names what were errors, and much others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
